# 02 텍스트 마이닝 첫걸음

> 비정형 데이터 중 텍스트 데이터로부터 유의미한 정보를 추출하는 텍스트 마이닝
> 	비정형: 정해진 형태가 없고, 연산이 불가능한 상태



# 핵심개념

1. 웹 크롤링으로 데이터를 수집
2. 키워드 추출의 방법
3. 키워드 간의 연관 관계 분석
4. 텍스트 분석 결과 시각화



# 2.1 웹크롤링으로 기초 데이터 수집하기

## 대상 페이지의 구조 살펴보기

> 가장 먼저 리스트의 url 정보를 수집해야 하는데 이 과정을 python 으로 자동화 하여 웹 크롤러를 만들자

## 웹 크롤링 라이브러리 사용하기

> 원하는 태그의 원하는 속성을 자동으로 가져오자

- request 라이브러리
  - 특정 url 로부터 html 문서를 가져옴
- BeautifulSoup4 모듈
  - Html 문서에서 데이터를 추출

```shell
pip3 install lxml beautifulsoup4 requests
```

## 텍스트 정보 수집하기

> get() 함수 말고 text() 함수를 사용해 태그의 텍스트 정보를 추출



# 2.2 나무위키 최근 변경 페이지 키워드 분석하기

## step 1. 크롤링: 웹데이터 가져오기

## step 2. 추출: 키워드 정보 추출하기

1. 수집한 데이터에서 키워드 정보만 추출하기 위해 **텍스트 전처리** 수행
   - 파이썬에서 're' 라는 모듈로 정규표현식으로 한글 이외의 문자는 전부 제거가능
   - 이는 텍스트 마이닝의 목적에 따라 다를 수 있음
2. 명사 혹은 형태소 단위의 문자열로 **키워드추출** 을 위해 **말뭉치** 를 만들어 리스트 반환
3. 해당 말뭉치들을 konlpy 라이브러리의 Okt 를 이용해 Counter 객체에 {'단어':'빈도'...} 형태로 만들 수 있음
   - 여기서 의미적인 독립이 불가능한 품사인 불용어를 불용어 사전과 비교해 없애줌

## step 3. 시각화: 워드 클라우드 시각화

> 워드 클라우드 라이브러리 많은데 그 중 pytagcloud 를 많이 씀

## 정리

| 핵심내용                           | 설명                                                         |
| ---------------------------------- | ------------------------------------------------------------ |
| 정규표현식을 활용한 텍스트 전처리  | 텍스트 분석 방향에 맞는 분자를 선별. 예제에서는 한글을 추출하기 위해 정규표현식 사용 |
| 형태소 분석기를 활용한 키워드 추출 | Konlpy 등의 형태소 분석기를 통해 데이터에서 키워드 추출      |
| 불용어 사전 적용                   | 많이 등장하지만 실질적 의미가 없는 불용어를 데이터에서 제거  |



# 2.3 특정 키워드가 있는 게시물 크롤링을 위해 트위터 API 사용

## 트위터 API 등록

1. 트위터 개발자 계정 등록
2. 개발자 앱 등록
   1. Key & tokens 얻어냄

## 파이썬 API 설정

> tweepy 라이브러리

발급된 트위터 key 들을 넣어주어 사용

# 2.4 트위터 API 로 '손흥민' 과 관련된 키워드 분석

- **연관분석**: 데이터의 집합으로부터 특정한 규칙 찾아냄, 아래 연관분석을 위한 평가지표들

  > 조건절을 A, 결과절을 B 라고 하자

  - 지지도(Support)

    - 전체중 A 와 B 가 동시에 일어날 확률
    - 둘다 포함하는 거래 수 / 전체 거래 수

  - 신뢰도(Confidence)

    - A 가 일어났다는 가정하에 B 가 일어날 확률
    - 지지도(Support) / P(A)

  - 향상도(Lift):

    - 임의로 B 가 발생하는 경우에 비해 A 와의 관계가 고려되어 구매되는 경우의 비율. 즉, A 가 B 를 예측하기 위해 능력이 얼마나 향상되었는가

    - 신뢰도(Confidence) / P(B)

      - | Lift   | 의미                | 예             |
        | ------ | ------------------- | -------------- |
        | 1      | 두 사건이 서로 독립 | 과자, 후추     |
        | 1 초과 | 양의 상관 관계      | 빵, 버터       |
        | 1 미만 | 음의 상관 관계      | 설사약, 변비약 |



## step 1. API 호출: 트위터 API 로 데이터 가져오기

> 데이터를 가져와 DF 형태로 정리하자

## step 2. 추출: 키워드 추출하기

1. 데이터 전처리
2. 피처간 연관분석에 용이하기 위해 **하나의 열 데이터 단위**로 키워드 추출

## step 3. 분석: 연관 분석을 이용한 키워드 분석

> apyori 라이브러리로 생성 가능한 모든 연관 규칙 중 빈발집합(Frequent sets) 만을 우선적으로 고려
> 	초월집합(Superset) 개념을 도입해 규칙의 형태를 제한

1. 연관분석 평가지표들로 조건을 설정해 연관분석 수행
2. 조건절과 결과절, 지지도 를 갖는 DF 생성
3. 빈도수가 50 미만인 키워드 제거하여 노드명과 빈도수를 갖는 DF 생성

## step 4. 시각화: 연관 키워드 네트워크 시각화하기

## 정리

| 핵심내용              | 설명                                                         |
| --------------------- | ------------------------------------------------------------ |
| 연관 규칙 분석        | 트랜잭션 데이터에 연관 규칙을 적용하고, 키워드 간의 지지도, 신뢰도, 향상도를 검토 |
| Apriori 알고리즘 적용 | 큰 규모의 데이터를 처리하기 위해서는 Apriori 와 같은 알고리즘을 도입. superset  을 이용해 빈도가 낮은 하위 집합을 가지치기 |

