# 04 데이터 분류모델

> 타이타닉 데이터로 예측하는 생존자 분석, 리뷰 데이터를 활용한 강남역 맛집 분류 분석



# 핵심 개념

1. 분류 분석의 개념을 이해
2. 분류 분석의 평가 기준
3. 피처 엔지니어링으로 더 나은 분석을 수행
4. 감성 분류



# 4.1 타이타닉의 생존자 가려내기

> 생존자 그룹과 비생존자 그룹을 분류하자

## step 1. 탐색: 타이타닉 데이터 살펴보기

1. 데이터셋의 구성을 살펴보자

2. 당장 분석에 활용할 수 없거나, 큰 의미를 가지고 있지 않은 피처를 제거 (name, cabin / ticket, home.dest, body)

3. 각 피처가 분류 분석에 미칠 영향에 대해 탐색

   1. 그룹별 피처

      - 생존자 그룹 / 비생존자 그룹 으로 나눈 후, 피처의 그룹 간 차이를 탐색

   2. 수치형 피처

      - 자동화 함수 **valid_feature()** 사용

        1. 두 그룹 간 분포를 비교하는 그래프 출력

        2. 두 그룹 각각의 표준편차 출력

        3. 두 그룹 간 T-test 검정

        4. 두 그룹 각각에 **Shapiro-wilk** 검정

           > 주어진 데이터가 얼마나 정규성을 따르는지, 즉 얼마나 정규분포에 가까운지

           - 예제에서는 age 피처와 sibsp 피처를 탐색했는데, age 피처는 두 그룹 간 평균 차이가 없기 때문에 생존에 미치는 영향력이 낮다고 가정할 수 있음

## step 2. 분류: 생존자 분류 모델 만들기

> 분류 모델 중 **로지스틱 회귀 모델 (Logistic regression)**로 분류 모델을 만들어보고, **의사결정나무모델(Decision Tree)**또한 간단히 살펴보자
>
> 로지스틱 회귀 모델은 예측값 y를 0 ~ 1 로 두어 0.5 를 기준으로 분류하는 방법

1. 결측값 처리

   > 결측치 삭제
   >
   > ​	주관이 개입되지 않으나, 중요 정보 삭제 위험
   >
   > 평균값, 혹은 중앙값이나 최빈값 등의 임의의 수치 대입 (예제에서 활용)
   >
   > ​	모든 데이터를 활용하나, 수치 왜곡 위험

2. 범주형데이터에 **원-핫 인코딩** 적용

   > Train, test 데이터셋 합친 후, 적용 후, 다시 분리

3. sklearn 모듈의 로지스틱 클래스로 모델 학습

4. 평가 (**Confusion Matrix** 활용)

   ![](https://miro.medium.com/max/2102/1*fxiTNIgOyvAombPJx5KGeA.png)

   - Description
     - TP: 관심범주를 정확하게 분류
     - FN: 관심범주가 아닌 것으로 잘못 분류
     - FP: 관심범주라고 분류한 것이 잘못
     - TN: 관심 범주가 아닌 것을 아니라고 정확히 분류
   - 지표
     - 정확도 (Accuracy): TP + TN / TP + TN + FP + FN
     - 정밀도 (Precision): TP / TP + FP
     - 재현도 (Recall): TP / TP + FN
     - 특이도 (Specificity): TN / TN + FP
   - 위 지표를 활용한 평가지표
     - **F1 - score** : 정밀도와 재현도의 조화 평균 (두 값을 동시에 고려할 때)
     - **ROC Curve**: 재현도와 특이도를 고려하여 종합적인 모델의 성능을 그래프로 나타낸 것, 그래프의 넓이는 **AUC(Area Under Curve)** 가 성능의 지표이며 1에 가까울수록 좋은 분류 모델

### 의사결정 나무 모델

피처 단위로 조건을 분기하여 정답의 집합을 좁혀나가는 방법. 로지스틱에 비해 모든 평가 지표가 낮음



## step 3. 모델 개선: 피처 엔지니어링 첫걸음

> 분류 모델의 성능을 끌어올리려면 어떻게 해야할까? '더 좋은 분류 기법' 이나 '더 많은 데이터' 도 좋은 방법이지만, 쉽게 적용할 수 있는 것이 아님.

### 피처 엔지니어링 (Feature engineering)

> 모델에 사용할 피처를 가공하는 분석 작업

초기에 cabin 피처와 name 피처를 제외했지만, 이 피처들을 가공하여 범주형 데이터로 가공하여 **F1 score** 와 **AUC** 가 대폭 상승했다.

분류 모델의 피처 영향력을 그래프로 살펴본 결과, **피처 엔지니어링**으로 생성된 name, cabin 피처의 영향력이 가장 컸다.

## step 4. 평가: 모델 검증하기

> 완성된 분류 모델을 검증하기 위해 **모델의 과적합 여부** 를 검정하자
>
> 그 방법으로 **K - fold 교차 검증** 과 **학습 곡선** 을 해보자

### K - fold 교차 검증

학습용 데이터셋과 테스트용 데이터셋이 균등하게 나누어졌는지 검증함

데이터를 k 개의 fold 로 나누어 k -1 개는 학습데이터, 나머지 1 개는 테스트 데이터로 사용해 k 번의 검증에서 점수 간 차이가 적다면, 과적합이 일어날 확률이 낮은 것.

### 학습 곡선

학습 데이터 샘플의 개수가 증가함에 따라 두 데이터셋의 점수가 어떻게 변하는지 관찰하는 그래프.

이를 통해 예제에서는 데이터가 300개 이상인 경우 과적합의 위험이 낮아진다는 것을 알 수 있다.

## 정리

| 주요 키워드        | 핵심 내용                                            | 설명                                                         |
| ------------------ | ---------------------------------------------------- | ------------------------------------------------------------ |
| 로지스틱 회귀 모델 | 로지스틱 회귀를 이용한 분류 모델                     | 모델의 결과인 0 ~ 1 사이의 확률값을 0, 1 로 분류하는 방법. 피처 영향력을 분석하기 용이한 장점 |
| 결측값 처리        | 모델 학습의 과정에서 결측값을 처리하는 방법          | 결측값을 처리하는 방법은 결츠값을 삭제해버리는 방법, 그리고 임의 의 수치로 채워 넣는 방법이 있음 |
| 분류 모델의 평가   | Confusion Matrix 를 기반으로 한 분류 모델의 평가지표 | Confusion Matrix 를 통해 계산된 Accuracy, Precision, Recall, F1-score, AUC 등의 수치로 분류 모델을 평가 |
| 분류 모델의 개선   | 피처 엔지니어링                                      | 피처 엔지니어링이란 모델의 사용할 피처를 가공하는 분석 작업을 의미 |
| 분류 모델의 검증   | 모델의 과적합을 검증                                 | 분류 모델의 성능을 검증하기 위해서는 모델의 과적합 여부를 판단 합니다. 그 방법으로 K - fold 교차검증, 학습 곡선의 관찰 등의 방법이 있음 |



# 4.2 강남역 맛집 리뷰로 알아보는 감성 분류

> 분류 모델의 대표적 활용방법인 **감성 분류** (텍스트 데이터를 긍정/부정 으로 분류)

## step 1. 크롤링: 네이버 플레이스 리뷰 크롤링

평점 4점 이상을 긍정(1) 리뷰로, 3점 이하를 부정(0) 리뷰로 평가해 수집하여 데이터셋을 만든다.

## step 2. 텍스트 전처리: 분류 모델 피처로 변환하기

> 텍스트 데이터를 감성분류의 피처로 사용할 수 있도록 전처리 해보자

1. 한글 정규 표현식으로 한글만 남김
2. 형태소를 추출
3. 텍스트 data 를 학습가능한 data set 으로 변환
   - raw data 에서 말뭉치형태로 변환하고, 각 텍스트에 어떤 말뭉치가 들어있는지 백터값으로 표기
   - 검토: 텍스트에 어떤 형태소가 있는데, 해당 피처의 벡터값이 있는 만큼 있는지 검증 + TF - IDF
     - TF - IDF (Term Frequency - Inverse Document Frequency): 해당 텍스트에서 단어가 몇 번 등장하는지에 대한 **TF** 와 모든 데이터에 해당 단어가 몇 번 등장하는지의 역수인 **IDF** 을 곱해 현재 문서에서 얼마나 중요한지를 피처로 나타낼 수 있음

## step 3. 분류: 긍정/부정 리뷰 분류하기

> 모두 준비가 되었으니 분류를 해보자

1. 학습 / 테스트 데이터셋으로 분류
2. 로지스틱 모델로 분류
   - 만약 평가 수치가 너무 높다면, Confusion Matrix 를 직접 확인해보자
   - ! 모든 데이터를 1 로 처리했다.
     - 이는 클래스의 불균형 문제 (데이터의 1, 0 비율이 크게 차이남)
     - 적절한 샘플링으로 클래스 개수를 맞춰주자



## step 4. 분석: 중요 키워드 분석하기

> 피처 영향력을 추출해보자.

계수를 양, 음으로 나누고 높은 순으로 정렬



## 정리

| 주요 키워드      | 핵심 내용                                    | 설명                                                         |
| ---------------- | -------------------------------------------- | ------------------------------------------------------------ |
| 감성 분류의 피처 | 텍스트를 분류 모델의 피처로 만드는 방법      | 텍스트를 피처로 사용하기 위해 말뭉치 개념을 사용합니다. 말뭉치에 등장한 형태소 셋(set) 만큼을 벡터의 길이로 한 뒤, 형태소 위치에 해당하는 피처의 값을 1 로 지정 |
| TF - IDF         | 단어의 중요도를 파악                         | 현재 문서에서의 빈도, 그리고 전체 문서에서의 빈도를 이용하여 단어의 중요도를 파악. 그리고 이를 피처로 사용 |
| 클래스 불균형    | 분류 모델에서의 클래스 불균형 문제           | 분류 모델에서는 Positive sample, Negative sample 의 비율때문에 클래스 불균형 발생 |
| 감성 키워드 분석 | 피처 영향력을 이용한 형태소 감성 키워드 분석 | 로지스틱 회귀 모델에서의 변수 중요도를 활용해 형태소의 감성 영향력을 분석할 수 있음 |

